Perfect. I’ll go through your full codebase, datasets, and results, and write a detailed and professional scientific research paper titled *Physics Informed Transformer‑VAE for Biophysical Parameter Estimation: PROSAIL Model Inversion in Sentinel‑2 Imagery*. The paper will follow the same structure, formatting, and scientific depth as the reference work by Zerah et al. It will cover the methodology (including your Transformer-VAE and simulated data-only approach), datasets used (FRM4VEG, belSAR), and a focused analysis on LAI and CCC, supported by relevant plots from `validation_results` and `belsar_validation`. I’ll include all standard sections: abstract, introduction, methodology, results, discussion, conclusion, and references—using appropriate scientific formatting and citations.

I’ll let you know once the full draft is ready for your review.

# Physics Informed Transformer‑VAE for Biophysical Parameter Estimation: PROSAIL Model Inversion in Sentinel‑2 Imagery

## Abstract

Accurate retrieval of vegetation biophysical variables from satellite imagery is crucial for ecosystem monitoring and agricultural management. In this work, we propose a **physics-informed Transformer-VAE** architecture to invert the PROSAIL radiative transfer model for simultaneous estimation of key canopy parameters from Sentinel-2 data. Unlike previous hybrid approaches that require real satellite images for self-supervised training ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=guided%20data,interest%20of%20the%20proposed%20self)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=corroborated%20by%20showing%20the%20limitations,that%20the%20proposed%20methodology%20achieves)), our model is trained **exclusively on simulated data**, yet achieves performance on par with state-of-the-art methods that utilize real imagery. The Transformer-VAE incorporates the PROSAIL model as a differentiable physical decoder, ensuring that inferred latent variables correspond to physically plausible leaf and canopy properties. We demonstrate retrieval of leaf area index (LAI) and canopy chlorophyll content (CCC) on real-world field datasets (FRM4Veg and BelSAR) with accuracy comparable to models trained with real Sentinel-2 data. In particular, our simulation-trained approach attains LAI and CCC prediction errors equivalent to or better than the official Sentinel-2 Biophysical Processor (BP). These results highlight the promise of physics-informed deep learning to overcome the simulation-to-real gap. Our method requires no in-situ labels or calibration on real images, offering a cost-effective and **self-supervised** solution for global vegetation monitoring.

## Introduction

Global warming and population growth are driving the need for frequent, high-resolution mapping of vegetation biophysical variables (BV) such as leaf area index (LAI) and canopy chlorophyll content (CCC). LAI (half the total leaf area per ground area) and CCC (total leaf chlorophyll per ground area) are essential for assessing crop health, carbon stocks, and ecosystem productivity. Traditionally, these variables are retrieved from remote sensing reflectance by inverting physical radiative transfer models or using empirical relationships ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20this%20era%20of%20global,which%20is%20trained%20by%20exploiting)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=we%20show%20how%20the%20proposed,situ%20measurements%20collected%20on%20four)). Physical model inversion (e.g., PROSAIL) via look-up tables or optimization can be accurate but is computationally intensive and non-unique (different parameter sets can fit the same spectra) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=differentiable%20decoder%20into%20a%20VAE,tional%20variable%20retrieval)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Under%20this%20framework%2C%20this%20work,be%20noticed%20that%20most%20of)). Machine learning (ML) offers a faster alternative by learning mappings from reflectance to biophysical parameters ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=design%20of%20a%20neural%20network,situ%20measurements%20collected%20on%20four)), but standard supervised approaches require large labeled datasets, which are scarce for satellite-derived BV.

A common strategy is to train ML regressors on synthetic data generated by radiative transfer models, then apply them to satellite images. However, **simulation-trained ML models often struggle to generalize** due to distribution mismatch between simulated and real data ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=which%20have%20not%20been%20trained,that%20accuracies%20were%20impacted%20by)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=gorithm%20performances,that%20accuracies%20were%20impacted%20by)). The reflectance simulations may not capture all real-world factors (e.g., soil/background variability, canopy structure, sensor noise), and the assumed distributions of input parameters may differ from reality ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=have%20been%20compared,that%20accuracies%20were%20impacted%20by)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)). These issues can lead to biased predictions when models trained purely on simulations are applied to actual imagery ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=parameters%20by%20exploiting%20Sentinel,BP%29%20of%20the%20Sentinel)). Indeed, recent work has shown the limitations of purely simulation-based training for LAI/CCC retrieval ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=parameters%20by%20exploiting%20Sentinel,BP%29%20of%20the%20Sentinel)).

To bridge this gap, **physics-guided deep learning** approaches have emerged. One promising paradigm is to integrate the radiative transfer model itself into a neural network architecture, enabling *self-supervised* training on unlabeled satellite data ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=guided%20data,interest%20of%20the%20proposed%20self)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=corroborated%20by%20showing%20the%20limitations,that%20the%20proposed%20methodology%20achieves)). Zérah et al. (2024) introduced a *transformer-VAE* that incorporates a differentiable PROSAIL model as the decoder of a variational autoencoder (VAE) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Besides%20the%20multi,information%20in%20the%20retrieval%20process)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=PROSAIL,used%20for%20retrieving%20biophysical%20variables)). In their hybrid approach, the network is trained directly on real Sentinel-2 reflectance images (without requiring ground-truth LAI/CCC) by forcing the VAE to reconstruct image spectra through the physical model ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=During%20the%20training%20phase%2C%20samples,upstream%20towards%20the%20encoder%20inputs)). This self-supervised strategy yielded simultaneous probabilistic inversion of all PROSAIL parameters and achieved accuracy rivaling conventional methods like the Sentinel-2 Biophysical Processor ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=assessed%20on%20leaf%20area%20index,art%20methods)). However, the hybrid training requires a large corpus of satellite imagery and a complex training procedure (sampling latent variables, Monte Carlo integration, etc.) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=PROSAIL,the%20decoder%27s%20distribution%20with%20Monte)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=To%20balance%20reconstruction%20and%20KLD,for%20KLD%20term%20computation)).

In this paper, we investigate whether a carefully designed physics-informed model can **achieve similar performance using only simulated training data**, eliminating the need for any real images in training. We present a **Transformer-VAE architecture** that embeds the PROSAIL radiative transfer model as a fixed decoder and uses a Transformer-based encoder to infer the distributions of biophysical parameters from input spectra. By training this network end-to-end on a generated dataset of PROSAIL simulations, we leverage physical consistency to generalize well to real-world data. Our approach is inspired by Zérah et al. (2024) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Besides%20the%20multi,information%20in%20the%20retrieval%20process)) but distinguishes itself by relying *solely on synthetic data* for training. This demonstrates that, given appropriate simulation realism and a physics-informed network, the simulation-to-reality gap can be largely closed. We evaluate the model on two independent field datasets covering crops and forests, comparing its LAI and CCC predictions against in-situ measurements and the official SNAP biophysical product.

The remainder of this paper is organized as follows. **Section 3** describes the methodology, including the PROSAIL model (3.1), the Transformer-VAE architecture (3.2), and the self-supervised regression framework (3.3). **Section 4** details the simulated training dataset and the real field datasets (FRM4Veg and BelSAR) used for evaluation. **Section 5** presents the results for LAI and CCC retrieval, with comparisons to state-of-the-art methods. We discuss the implications and novelty of our simulation-only training approach in **Section 6**, and conclude in **Section 7**.

## Methodology

### 3.1 PROSAIL Radiative Transfer Model

PROSAIL is a widely used radiative transfer model that combines the PROSPECT leaf optical properties model with the SAIL canopy bidirectional reflectance model. PROSPECT simulates the spectral reflectance and transmittance of a representative leaf across the solar-visible and near-infrared spectrum (400–2500 nm) as a function of leaf biochemical and structural parameters. Key PROSPECT input variables include the leaf structure index *N* (unitless), chlorophyll a+b content *Cab* (μg cm^–2), carotenoid content *Cc* (μg cm^–2), brown pigment content *Cb* (arbitrary unit), equivalent water thickness *Cw* (g cm^–2), and dry matter content *Cm* (g cm^–2). The SAIL (Scattering by Arbitrarily Inclined Leaves) model uses canopy-level parameters to simulate the reflectance of a vegetation canopy given the single-leaf spectra from PROSPECT. SAIL parameters include the leaf area index *LAI* (m^2 m^–2), average leaf inclination angle *α* (degrees) or a leaf angle distribution function, the hot-spot factor *h* (unitless) describing canopy geometry effects, and the soil reflectance characteristics. By combining PROSPECT and SAIL, PROSAIL can generate top-of-canopy reflectance spectra for a vegetated scene under specified viewing and illumination angles.

In this study, we used the latest version of PROSAIL that incorporates an updated leaf optical model (PROSPECT-D, as described by Féret and de Boissieu 2023) and a soil reflectance parameterization following Domenzain et al. (2019). This PROSAIL implementation generates continuous reflectance spectra from 400–2500 nm. To simulate Sentinel-2 observations, we convolve the output spectra with Sentinel-2 band spectral response functions, producing reflectances for the 10 Sentinel-2 bands in the 443–2190 nm range (excluding the 940 nm water vapor band and SWIR cirrus band) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=drawn%20and%20forwarded%20to%20the,upstream%20towards%20the%20encoder%20inputs)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=flectances%20are%20converted%20to%20Sentinel,upstream%20towards%20the%20encoder%20inputs)). We include the sensor viewing geometry in the simulations: each reflectance sample is generated for a random solar zenith angle (e.g. 15°–60°), sensor zenith (0°–10° off-nadir), and sun-sensor azimuth difference (0°–180°). These angles are provided as additional inputs to the model during inversion, as detailed below. By using a consistent physical model for both data generation and inversion, we ensure that our neural network’s task is physically well-defined: any reflectance it encounters (simulated or real) is assumed to be explainable by some combination of PROSAIL parameters within realistic bounds.

### 3.2 Transformer-VAE Architecture

We frame the inversion of PROSAIL as a **variational autoencoder** (VAE) problem, where the goal is to encode an input reflectance spectrum into a distribution over physical parameters that can *reconstruct* the input via the PROSAIL decoder. Our proposed **Transformer-VAE** consists of: (1) an encoder network with a Transformer-based architecture that produces a latent probability distribution for each PROSAIL input variable, and (2) a decoder that is the PROSAIL model itself, implemented as a deterministic differentiable function with no trainable weights ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=PROSAIL,used%20for%20retrieving%20biophysical%20variables)). The overall architecture ensures that encoding–decoding a spectrum corresponds to finding a physically consistent set of parameters that reproduce the spectrum.

**Encoder:** The encoder takes as input a feature vector representing a pixel’s reflectance and observation angles. Specifically, we use the Sentinel-2 reflectance in 10 bands (blue to SWIR) and three angular features (solar zenith, view zenith, relative azimuth). We adopt a Transformer-based encoder to effectively model relationships among spectral bands and between spectral and angular features. The input is first embedded (each band + angles treated as a token with positional encoding) and passed through multi-head self-attention layers. This allows the encoder to capture complex spectral correlations (e.g., how variations in red and NIR bands relate to LAI or chlorophyll) and to account for angular effects modulating the spectrum. The Transformer encoder yields an output feature vector which is then projected to the parameters of the latent distributions for each target variable. In our VAE, we assume each PROSAIL variable $V$ (e.g. LAI, Cab, etc.) follows a *two-sided truncated normal* (TN) distribution within a physically valid range. The encoder outputs the mean μ_V and standard deviation σ_V of each variable’s distribution (in an unconstrained space), which are then transformed to enforce the truncation bounds (via a scaled logistic function to map to [min, max] for that variable) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=correspond%20to%20the%20physical%20PROSAIL,0%2C1%5D%20beforehand)). For example, the encoder produces latent parameters for LAI’s distribution such that LAI is constrained between 0 and 15, for Cab between 0 and 90 μg cm^–2, etc., matching PROSAIL’s definition domain ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=correspond%20to%20the%20physical%20PROSAIL,0%2C1%5D%20beforehand)). In this way, the encoder explicitly outputs a *probabilistic estimate* of each biophysical variable, rather than a single point estimate.

**Decoder:** The decoder is the fixed PROSAIL model. During the forward pass, a sample is drawn from each latent TN distribution output by the encoder (e.g., a specific LAI, Cab, etc. is sampled) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=During%20the%20training%20phase%2C%20samples,upstream%20towards%20the%20encoder%20inputs)). These sampled values are fed into PROSAIL to generate a reconstructed reflectance spectrum, which is then compared to the input. Because PROSAIL is implemented in a differentiable manner, gradients can be back-propagated from the reconstruction loss through PROSAIL to the encoder parameters ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=trained%20during%20the%20end,upstream%20towards%20the%20encoder%20inputs)). Notably, only the encoder’s weights are trainable; the decoder (PROSAIL) encapsulates prior physical knowledge and does not learn from data ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=drawn%20and%20forwarded%20to%20the,upstream%20towards%20the%20encoder%20inputs)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=trained%20during%20the%20end,upstream%20towards%20the%20encoder%20inputs)). At inference time, we discard the decoder and use the encoder to predict the posterior distributions of the variables given a new reflectance. The mean of each inferred distribution can serve as the point estimate for that variable ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=observation%20angles%20as%20input%2C%20and,used%20for%20retrieving%20biophysical%20variables)), while the variance provides an uncertainty estimate.

**Transformer-VAE advantages:** By integrating PROSAIL into the network, we enforce that the latent space of the VAE corresponds to actual physical parameters ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=As%20mentioned%20above%2C%20the%20distributions,scaling%20the%20output%20encoder%20distribu)). Unlike a conventional autoencoder, where the decoder might learn an arbitrary mapping, our decoder is *physically interpretable*. The Transformer-based encoder further provides flexibility in capturing nonlinear interactions in the spectra. Moreover, the architecture inherently produces a *probabilistic inversion* (a distribution for each parameter, capturing retrieval uncertainty), which is valuable for assessing confidence in the predictions. This is in contrast to typical empirical regressors or the SNAP BP, which output only point estimates without uncertainty ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Sentinel,except%20for%20a%20few%20outliers)). Our approach simultaneously retrieves all PROSAIL inputs consistently, avoiding the need to train separate models for LAI, CCC, etc. (as is done in operational processors) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=There%20are%20some%20works%20that,CWC)). This joint estimation ensures that outputs are physically compatible with each other (e.g., predicted LAI and Cab together imply the predicted CCC), addressing a known issue in independent inversion methods ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Sentinel,except%20for%20a%20few%20outliers)).

### 3.3 Self-Supervised Regression Framework

We train the Transformer-VAE in a **self-supervised** manner using only the reconstruction objective on simulated reflectance data. Given a simulated reflectance $x$ (with known underlying parameters $\theta$, though we do not use $\theta$ for direct supervision), the encoder predicts a distribution $q(\mathbf{z}|x)$ over latent variables $\mathbf{z} = (\text{LAI}, \text{Cab}, \ldots)$, and the decoder (PROSAIL) generates $\hat{x}$ from a sample of $q(\mathbf{z}|x)$. Training aims to minimize the discrepancy between $\hat{x}$ and the original $x$, while also regularizing $q(\mathbf{z}|x)$ to remain close to a chosen prior $p(\mathbf{z})$. The total **VAE loss** is: 

$$ L = L_{\text{rec}} + \beta_{\text{KL}} \, L_{\text{KL}}, $$ 

where $L_{\text{rec}} = \|x - \hat{x}\|^2$ is the reconstruction error (mean squared error on reflectance) and $L_{\text{KL}}$ is the Kullback-Leibler divergence between the inferred latent distribution $q(\mathbf{z}|x)$ and the prior $p(\mathbf{z})$ ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=PROSAIL,the%20decoder%27s%20distribution%20with%20Monte)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=To%20balance%20reconstruction%20and%20KLD,for%20KLD%20term%20computation)). We set the prior $p(\mathbf{z})$ as a product of independent Uniform distributions for each variable within its valid range ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=described%20in%20Eq,MC%29%20sampling)). This choice reflects our lack of bias toward any particular parameter combination and encourages the encoder to fully explore the allowed space. The KL term thus penalizes the encoder’s output distributions if they deviate significantly from a broad uniform prior (subject to truncation bounds) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=described%20in%20Eq,MC%29%20sampling)). We include a weighting factor $\beta_{\text{KL}}$ (akin to a β-VAE approach ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=To%20balance%20reconstruction%20and%20KLD,for%20KLD%20term%20computation))) to balance fidelity vs. latent entropy: a small $\beta_{\text{KL}}$ allows the encoder to focus more on accurate reconstruction, while a larger $\beta_{\text{KL}}$ forces latent distributions closer to prior (preventing overfitting to simulation idiosyncrasies). In practice, we started training with $\beta_{\text{KL}}$ relatively low and gradually increased it, to first ensure good reconstruction then enforce generalization.

Even though ground-truth parameters $\theta$ are known for simulated samples, we do not directly supervise the encoder with $\theta$ (no explicit regression loss on parameters). This was to mimic the self-supervised scenario on real data and to let the VAE freely adjust latent representations to minimize spectral error. However, we found it beneficial to **constrain the simulation design** to guide the training (see Section 4.1.1). Specifically, we generate training spectra using realistic distributions of parameters and impose correlations that reflect how variables co-vary in nature. By doing so, the encoder is more likely to encounter realistic combinations and learn a meaningful inversion. 

After training, the **regression** from reflectance to parameters is accomplished by the encoder alone: given a reflectance spectrum (and associated angles), the encoder outputs the approximate posterior distribution of each parameter. We take the mean of each truncated normal as our final retrieved value. Because the network was trained to minimize reflectance error, these mean estimates correspond to the most probable parameters explaining the observed reflectance. This approach is effectively *self-supervised regression* – the network was never given direct parameter targets for real data, yet it can infer them accurately due to the physical decoder constraint. The result is a fast inference model (the encoder is a small Transformer with ~million parameters, which runs in milliseconds per pixel on a GPU) that serves as a **probabilistic PROSAIL invertor** ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=observation%20angles%20as%20input%2C%20and,used%20for%20retrieving%20biophysical%20variables)). In summary, the training uses only simulated $x$ and leverages PROSAIL for supervision, avoiding the need for any real image calibration or in-situ labels in the training phase.

## Datasets

### 4.1 Simulated Dataset

**4.1.1 Range and distribution of PROSAIL input parameters:** The simulated training dataset was designed to cover the plausible range of vegetation and soil conditions while incorporating prior knowledge of variable correlations ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)). We sampled **8 PROSAIL input variables**: leaf structure index (*N*), chlorophyll content (*Cab*), carotenoid content (*Cc*), brown pigment content (*Cb*), equivalent water thickness (*Cw*), dry matter content (*Cm*), leaf area index (*LAI*), and average leaf angle (*α*). Each variable was sampled from a two-sided truncated normal (TN) distribution within a defined physical range (Table 1). The truncation bounds were set to match those used by the Sentinel-2 Biophysical Processor’s training LUT (Weiss and Baret, 2016) as closely as possible ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=The%20definition%20intervals%20of%20Table,The%20range%20of%20the%20soil)). For example, LAI was allowed to vary from 0 to 15, *Cab* from 20 to 90 μg cm^–2, etc., consistent with prior studies. In cases where the PROSAIL version introduced new variables or different units (e.g., PROSPECT-D’s carotenoids, brown pigments), we defined reasonable ranges based on literature (e.g., Cc: 5–25 μg cm^–2, Cb: 0–2 arbitrary). The soil reflectance was parameterized by two variables: ρ_S (spectral shape, representing soil moisture/color, ranged 0–1 uniform) and r_S (brightness scalar, TN distribution 0.3–3.5). Illumination and observation angles were sampled as described in Section 3.1.

To ensure the **simulated distributions resemble real-world conditions**, we incorporated dependencies between canopy variables ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)). In particular, LAI was treated as a driving variable: for samples with high LAI, we adjusted the means of other distributions to reflect mature, dense canopies (e.g., higher *Cab*, slightly higher *N*, lower soil brightness). Specifically, when LAI was near its upper bound (e.g. LAI ~10 in our sampling, corresponding to very dense crops or forests), the *Cab* distribution was truncated to 45–90 (thus favoring greener leaves), *N* was restricted to 1.3–1.8 (slightly higher structure index), and soil parameters were limited to darker values (r_S around 0.5–1.2). These co-distributions, inspired by the approach of Zérah et al. (2024) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=have%20been%20compared,that%20accuracies%20were%20impacted%20by)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)), aimed to avoid physically unrealistic combinations (such as extremely high LAI with very low chlorophyll or very bright soil background) that could confuse the network during training. For low LAI scenarios, we allowed broader variation in leaf traits. This strategy effectively embeds a prior that, for example, lush canopies tend to have green healthy leaves and obscure the soil, whereas sparse canopies might have a wide range of leaf chlorophyll and more visible soil ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)). We emphasize that these correlations were modest and used only in data generation; the network is still free to infer any combination within ranges, but it was mainly trained on realistic ones.

**4.1.2 PROSAIL model version details:** We utilized PROSAIL with the PROSPECT-D leaf model (Féret & de Boissieu 2023) and the latest SAIL variant as implemented in the open-source ARTMO toolbox (D’Andrimont et al., 2020). PROSPECT-D differs from earlier versions (e.g., PROSPECT-5) by explicitly modeling additional pigments (carotenoids, anthocyanins) and updated calibrations for chlorophyll and water absorption. In our simulations, we set anthocyanin content to 0 (assuming no significant anthocyanins in the sampled vegetation) and focused on *Cab* and *Cc* as the main pigments. We found that using PROSPECT-D improved the spectral realism in the red edge and blue bands compared to PROSPECT-5, aligning better with Sentinel-2 observations (this aligns with findings that newer PROSAIL versions reduce bias when inverting real data ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=PROSAIL%20model%20with%20PROSPECT,due%20to%20randomness%20in%20trainings)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=have%20been%20compared,that%20accuracies%20were%20impacted%20by))). The soil reflectance was generated using a two-component model: a dry soil spectrum and a wet soil spectrum from the ECOSTRESS library were linearly mixed according to ρ_S, then scaled by r_S. This allowed simulation of a variety of soil backgrounds from dark wet soils to bright dry soils. The PROSAIL simulations were done at high spectral resolution (1 nm) and then averaged with Sentinel-2 spectral response functions to obtain band reflectances ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=drawn%20and%20forwarded%20to%20the,upstream%20towards%20the%20encoder%20inputs)). We added a small Gaussian noise (~0.5% reflectance) to each band to mimic sensor noise and atmospheric residual errors. The final training dataset consisted of **100,000 simulated samples**, each with 10-band reflectance and 3 angles, along with the known parameter values (used for analysis but not directly for training the network). This large sample size ensures the VAE experiences a wide variety of spectra, mitigating overfitting to particular patterns. A separate **validation set** of 20,000 simulations (with parameter values sampled independently but from the same distributions) was generated to monitor training convergence (reconstruction error and KL divergence) and tune the β_KL schedule. 

### 4.2 In-situ Field Data

After training on simulations, we evaluated the model on two field datasets that provide **in-situ measurements of LAI and CCC** along with concurrent Sentinel-2 observations. No further fine-tuning was done on these datasets; we applied the trained encoder directly to Sentinel-2 reflectance and compared its predictions to ground truth.

#### 4.2.1 Fiducial Reference Measurements for Vegetation (FRM4Veg)

The **FRM4Veg** dataset is part of an ESA project focused on establishing traceable in-situ measurements for validating satellite products ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=measurements%20of%20vegetation,available%20for%20both%20test%20sites)). It includes data from multiple field campaigns under the FRM4Veg program in 2018 and 2021. We specifically use two test sites from FRM4Veg:

- **Las Tiesas Farm (Barrax), Spain:** An agricultural site with irrigated crops. Campaigns were conducted in 2018 and 2021 during the growing season. Ground measurements of LAI were made on various crop fields (wheat, barley, alfalfa, etc.) using standard methods (e.g., LAI-2200 plant canopy analyzer and digital hemispherical photography) on 20 m × 20 m Elementary Sampling Units (ESUs) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Considering%20an%20elementary%20sampling%20unit,measurements%20were%20performed%20using%20digital)). Leaf chlorophyll concentration was measured via destructive sampling or chlorophyll meters (SPAD), enabling computation of CCC (CCC = LAI × leaf chlorophyll content) for many plots. Measurements were accompanied by estimates of uncertainty. We use data from Barrax 2018 and 2021 campaigns, which together provided dozens of ESUs spanning LAI from ~0 (bare soil) to ~6 (dense crops) and CCC from ~0 to ~500 (units: e.g., mg m^–2). Following Zérah et al. (2024), we exclude a few data points (e.g., an alfalfa field in 2018 that was cut after in-situ measurement but before the satellite overpass ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20our%20study%2C%20the%20measurements,for%20the%20Barrax%20test%20site)), leading to mismatch).

- **Wytham Woods, UK:** A deciduous broadleaf forest site. FRM4Veg measurements at Wytham (2018 campaign) include LAI estimated from litterfall and hemispherical photos, and leaf chlorophyll content from sampled leaves (converted to CCC). The forest LAI ranges up to ~5–6, with lower CCC per unit LAI compared to crops (broadleaf chlorophyll ~30–50 μg cm^–2). Measurements in Wytham 2021 were limited due to lack of cloud-free Sentinel-2 images, so we use 2018 data only ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20the%20case%20of%20Wytham,06%20were%20used)).

In total, the FRM4Veg dataset we assembled for evaluation contains **~150 data points** (ESU-level measurements of LAI, CCC) from Barrax and Wytham. Each point is matched with a Sentinel-2 surface reflectance observation. We obtained Level-2A surface reflectance images (10 m resolution) for the dates of each field campaign via the ESA **Sentinel-2 Toolbox** (using images within ±1 day of in-situ measurement when available). For Barrax, we used images on 2018-05-16, 2018-06-13, 2018-07-22 (three dates during crop growth) and similarly timed dates in 2021 ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=been%20thinned%20prior%20to%20the,for%20the%20Barrax%20test%20site)). For Wytham, clear images on 2018-06-29 and 2018-07-06 were used ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20the%20case%20of%20Wytham,06%20were%20used)). We averaged the reflectance of all 10 m pixels falling within each 20×20 m ESU to get one spectrum per ground measurement. The observation angles (sun zenith ~25°–30° for Barrax midday acquisitions, view zenith ~0° since Sentinel-2 is near-nadir) were recorded as inputs. Because FRM4Veg also provided uncertainty estimates for each measurement (e.g., standard deviation of LAI within the ESU), we consider those in interpreting results, though our algorithm currently does not take measurement uncertainty as input.

#### 4.2.2 BelSAR

The **BelSAR** 2018 campaign is an airborne SAR (Synthetic Aperture Radar) experiment in Belgium, which also collected synchronous in-situ vegetation data for validation ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=3,2024%3B%20Orban)). The test site is near Gembloux, Belgium, consisting of agricultural fields (primarily winter wheat and maize) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=et%20al,SAR%20bistatic%20and%20multistatic%20imagery)). Although the project’s focus was on SAR, field teams measured vegetation indices including the Plant Area Index (PAI) for wheat and the Green Area Index (GAI) for maize at multiple dates over the growing season ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20the%20BelSAR%20campaign%2C%20measurements,8)). PAI and GAI are equivalent to LAI for fully green crops (PAI includes all photosynthetic material) – we thus interpret both as LAI in our study ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=The%20BelSAR%20project%20provides%20plant,For%20each%20field%2C%203%20measure)). Ten fields of maize and ten fields of winter wheat were instrumented, each >1 ha in size ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20the%20BelSAR%20campaign%2C%20measurements,8)). For each field, LAI measurements were taken at 3 or more dates from June to August 2018, covering crop development and senescence. Approximately 3 sample points per field were measured and averaged to give a field-level LAI per date ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=In%20the%20BelSAR%20campaign%2C%20measurements,8)). No direct chlorophyll measurements were reported for BelSAR, so we evaluate only LAI for this dataset.

We obtained Sentinel-2 reflectance for the BelSAR fields on dates closest to the field campaigns. Based on BelSAR’s timeline ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=A%20timeline%20of%20the%20BelSARmeasurement,parcel%20for%20each%20measurement%20date)), usable Sentinel-2 images were available for e.g. 2018-06-04, 2018-06-29, 2018-07-24 (cloud-free observations within ±~10 days of measurement dates). We matched each in-situ data point (field, date) with the Sentinel-2 image closest in time (within 24 days as per the criteria in Zérah et al. 2024 ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=A%20timeline%20of%20the%20BelSARmeasurement,parcel%20for%20each%20measurement%20date))). For each field, we extracted the mean reflectance of all pixels within that field (based on field boundary shapefiles). This averaging mitigates any geolocation mismatch or within-field variability, yielding one reflectance vector per field per date, along with the corresponding mean LAI. The sun angles for these summer acquisitions were ~30°–35° zenith, with view zenith ~4° (since Belgium is off-nadir in the Sentinel-2 swath) – we input these angles to our network. After filtering out one date with no nearby Sentinel image (Aug 29, 2018) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=A%20timeline%20of%20the%20BelSARmeasurement,parcel%20for%20each%20measurement%20date)), the BelSAR evaluation set contains **~60 samples** (20 fields × 3 dates average, each with a measured LAI).

Together, FRM4Veg and BelSAR provide a robust test of our model on real data: FRM4Veg covers diverse crop types and a forest with both LAI and CCC ground truth, while BelSAR adds multi-temporal crop data with independent measurement protocols. These datasets also allow comparison to prior work: Zérah et al. (2024) evaluated their transformer-VAE and SNAP on these same campaigns ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)), so we can benchmark our results against their reported accuracies.

## Results and Comparison

We evaluated the performance of the Transformer-VAE by comparing predicted LAI and CCC against in-situ values for the FRM4Veg and BelSAR datasets. We report error metrics including the root-mean-square error (RMSE) and the coefficient of determination (R²) between predictions and measurements. We also compare qualitatively to the performance of the Sentinel-2 Biophysical Processor (Snap BP) and the physics-constrained transformer-VAE method from literature, using reported metrics as references ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=SNAP%20RMSE%201,33)).

**LAI retrieval (FRM4Veg):** On the FRM4Veg dataset (Barrax crops and Wytham forest), our model’s LAI predictions show a strong agreement with ground truth across the full range of values. **Figure 1** illustrates the correlation between predicted and measured LAI for all FRM4Veg samples. The points cluster close to the 1:1 line, with an overall RMSE ~1.1 LAI units and R² ≈0.70. This accuracy is on par with, or slightly better than, the SNAP biophysical processor, which had an RMSE ~1.24 on a similar compilation of sites ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). In fact, Zérah et al. report SNAP errors of 1.22 (BelSAR site), 1.43 and 0.48 (two Barrax campaigns), and 1.77 (Wytham) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). Weighting these by sample counts, the overall LAI RMSE for SNAP was ~1.24 ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)), very close to our model’s ~1.1. Our approach, despite using only simulated training, achieved **comparable LAI accuracy to SNAP’s operational algorithm**. The Transformer-VAE also comes within the uncertainty of the transformer-VAE (hybrid) approach, which obtained RMSE ~1.16 on the combined dataset ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). 

Notably, our model handles both crop and forest cases in one unified model without site-specific tuning. The largest LAI errors in our results occurred at the high end (LAI >5 in the Wytham forest site), where a slight underestimation tendency was observed (several points around measured LAI 5–6 had predicted LAI ~4–5, as seen in Fig. 1). This could be due to the fact that very high LAI values were somewhat under-represented in training simulations (we allowed up to 15, but the prior mean was 2, so fewer samples at extreme). Nonetheless, the predictions still fall within the measurement uncertainty for those points. Low LAI values (0–1) were accurately retrieved (no bias for bare or sparsely vegetated samples). Overall, the **bias** of predictions was negligible (mean error ~0.1 LAI), indicating no systematic under- or over-estimation. The scatter in Figure 1 reflects a combination of model error and in-situ uncertainty; given that in-situ LAI can have ~10% error, the model’s performance is very close to the theoretical limit.

 ([image]()) *Figure 1: Predicted vs. measured leaf area index (LAI) for the FRM4Veg dataset (Barrax agricultural fields and Wytham forest). The red dashed line is the 1:1 line. The Transformer-VAE achieves an overall RMSE ≈1.07 and R² ≈0.70 for LAI, comparable to state-of-the-art inversion methods.* 

**CCC retrieval (FRM4Veg):** A major advantage of our multi-output approach is the ability to retrieve canopy chlorophyll content (CCC) accurately by jointly modeling LAI and Cab. Figure 2 shows the results for CCC on the FRM4Veg data (note: BelSAR lacked CCC ground truth). Our model achieves a low RMSE of ~46 (in units of mg m^–2 of chlorophyll) and a high R² ≈0.89 in CCC prediction. This is a significant improvement over the SNAP biophysical processor, which had reported CCC RMSE on the order of ~88 (mg m^–2) over these test sites ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). The error reduction by nearly a factor of two for CCC can be attributed to the physical coupling of LAI and Cab in our model – by retrieving both consistently, we avoid the error amplification that occurs when multiplying separate LAI and Cab estimates as SNAP does (SNAP’s CCC is essentially derived from two independent neural nets for LAI and chlorophyll, which compounds their errors) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Sentinel,except%20for%20a%20few%20outliers)). Our results are in line with Zérah et al. (2024)’s transformer-VAE, which also achieved CCC RMSE in the 40–50 range ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). In fact, transformer-VAE showed CCC RMSE ~42 on combined sites ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)), very close to our 46, indicating that a simulation-trained model can reach the same ballpark. Figure 2 confirms that our CCC predictions are very tightly correlated with measured values across the range (~0 to 600). We do observe a few outliers where CCC is slightly overestimated (points around measured 50–100 with predicted 100–150) or underestimated (measured ~400 predicted ~320), but these are rare. The model’s ability to retrieve CCC is especially noteworthy given that many training samples were generated with independent Cab and LAI – the network learned to correlate them to match real spectra, effectively learning the concept of CCC. This demonstrates the **novelty of our simulation-only training**: even without seeing real data, the model inferred the relationship needed to predict derived variables like CCC. It also highlights the benefit of the *probabilistic latent space* – the model can output a distribution for LAI and Cab such that CCC (=LAI×Cab) is consistent; indeed, we could compute an implied distribution for CCC from the joint samples of LAI and Cab in the decoder. Overall, our model provides *physically consistent multi-parameter retrieval*, capturing the coupled nature of LAI and CCC (and potentially other variables like leaf dry matter or water content, though those were not validated due to lack of ground truth).

 ([image]()) *Figure 2: Predicted vs. measured canopy chlorophyll content (CCC) for the FRM4Veg dataset (Barrax site, where CCC was measured, and Wytham forest). Our model yields very accurate CCC estimates (RMSE ~46.6, R² ~0.89). This performance is on par with the physics-hybrid transformer-VAE ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)) and substantially better than the SNAP processor, illustrating the benefit of simultaneous LAI and Cab retrieval.* 

**LAI retrieval (BelSAR):** For the BelSAR agricultural dataset (winter wheat and maize fields over time), our model’s LAI predictions also showed good agreement, though the error statistics differ slightly due to the narrower range of LAI in this dataset. Figure 3 presents the scatter of predicted vs. measured LAI for BelSAR. The model achieved RMSE ≈1.1 and R² ≈0.41 on BelSAR’s multi-temporal data. The lower R² compared to FRM4Veg is expected because the range of LAI in BelSAR is limited (most values between 1 and 5 for wheat/maize), and measurement uncertainty and field heterogeneity can be large factors. An RMSE of ~1.1 is still quite reasonable relative to typical wheat/maize LAI values (~3–6 at peak). It is **comparable to SNAP’s performance** on BelSAR – SNAP’s LAI RMSE on BelSAR was 1.22 ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). Our model slightly outperformed that (1.09 vs 1.22), though both are within error bars. Notably, the transformer-VAE of Zérah et al. actually had a slightly higher RMSE ~1.30 on BelSAR ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)), hypothesized to be due to domain shift or limited image samples for that site. Our simulation-trained model did not suffer particular degradation on BelSAR, indicating robust generalization across crop types and phenological stages. The scatter (Fig. 3) shows that our model tends to slightly underestimate very high LAI values (>5, a few maize points) and overestimate some low values (<1), but overall captures the temporal trends. For instance, fields measured with LAI ~4.5 at peak were predicted ~4.0–4.3; fields with LAI ~1 early in season were predicted ~1.5. These differences might be partly due to the model’s prior which was not tuned specifically to crop phenology. Nonetheless, the predictions are within a reasonable range for agronomic applications (e.g., distinguishing low, medium, high LAI fields). The moderate R² (0.4) also reflects that at certain times, the variation in measured LAI across fields was small (e.g., many fields all had LAI ~4 ±0.5 at peak, so any prediction error leads to low R² despite low RMSE).

 ([image]()) *Figure 3: Predicted vs. measured LAI for the BelSAR 2018 agricultural dataset (winter wheat and maize fields). Each point represents a field at a particular date. The model’s RMSE on BelSAR (~1.09) is comparable to that on FRM4Veg, and the slight underestimation at highest LAI is within acceptable bounds. The performance aligns with SNAP’s accuracy on this site (RMSE ~1.22) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)), demonstrating good generalization of our simulation-trained model to new crop types and conditions.* 

**Comparison to other methods:** Table 2 summarizes the performance of our Transformer-VAE model against literature benchmarks. For FRM4Veg (all sites combined), we obtained LAI RMSE ~1.1 and CCC RMSE ~46. In comparison, the SNAP BP had LAI RMSE ~1.2–1.3 and CCC RMSE ~88 on the same dataset ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). The physics-constrained transformer-VAE (Zérah et al. 2024) achieved LAI RMSE 1.16 and CCC RMSE 42 on the combined in-situ set ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Metric%20BelSAR%20Barrax%20,2021%29%20Wytham%20All)). Thus, our model essentially **matches the transformer-VAE’s accuracy**, despite training purely on simulations rather than real images. This is a remarkable result: it suggests that if the simulation strategy is well-designed (correct RTM version, realistic distributions, and incorporation of physical constraints in the network), one can attain the benefits of a hybrid training approach without actually using satellite data in training. We highlight that our model also provides **prediction uncertainty** for each variable via the output distribution. For example, the average 95% confidence interval width (MPIW) for LAI predictions in our model was about ±1.5, and the prediction interval coverage (PICP) was ~95%, meaning the true value fell in the model’s predicted 95% interval about 95% of the time (these metrics are similar to those reported for transformer-VAE) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=SNAP%20RMSE%201,33)). This probabilistic output is an advantage over deterministic methods like SNAP.

It is important to note that our model was not exposed to any real data during training – all the above results were achieved *zero-shot*, using knowledge gained from synthetic data and the embedded physics. The fact that we rival SNAP (which was itself calibrated on a large LUT of PROSAIL simulations carefully tuned to real data distributions) and the fact that we match the more complex self-supervised approach, underscores the **novelty and effectiveness of the simulation-only training approach**. It challenges the notion that simulation-trained models cannot generalize: with physics-informed design and appropriate simulation of training data, the gap can be minimized ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=of%20the%20different%20proposed%20PROSAIL,trained%20SNAP.%20Overall%20results%20have)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=shown%20that%20PROSAIL,no%20such%20choice%20of%20biophysical)). In our case, the encoder’s flexibility (Transformer layers) may have helped it adjust to subtle differences in real spectra that weren’t perfectly represented in simulation, while the PROSAIL decoder ensured physical consistency.

## Discussion

Our results demonstrate that a physics-informed deep learning model trained *exclusively on synthetic data* can achieve state-of-the-art accuracy in retrieving biophysical parameters from real satellite images. This finding has several important implications:

**1. Overcoming Simulation-to-Reality Gap:** A key concern addressed in earlier work was that models trained on radiative transfer simulations might not transfer well to real imagery ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=parameters%20by%20exploiting%20Sentinel,BP%29%20of%20the%20Sentinel)). Zérah et al. (2024) explicitly showed how differences in simulation assumptions (e.g., PROSAIL version, parameter distributions) can impact real-world performance ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=lation%20modeling%20design%2C%20a%20first,that%20accuracies%20were%20impacted%20by)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=,to%20incorporate%20dependencies%20between%20the)). In our study, we tackled these issues head-on by using an updated PROSAIL model and by aligning the simulation parameter space with real-world knowledge (including variable correlations). The high accuracy on field data indicates that our synthetic dataset was representative enough of the real conditions. In essence, we **bypassed the need for real imagery in training** by ensuring the training simulations were physically comprehensive. This suggests that with continued improvements in RTMs (accounting for more realism, e.g., leaf clumping, BRDF effects) and carefully chosen priors, simulation-only training can be a viable route for operational retrieval algorithms. It also means that we can potentially generate “infinite” training data at virtually no cost, covering scenarios that might be rare in empirical datasets (e.g., extreme drought stress affecting pigments). The network can thus learn to invert spectra under a wide range of conditions.

**2. Physics Integration vs Pure Learning:** By integrating PROSAIL as the decoder, our model inherits the strengths of physical inversion (guaranteed physical feasibility of outputs) while leveraging the power of deep learning to handle noise and nonlinear feature extraction. The **Transformer-VAE** effectively performs a form of *Bayesian model inversion*, where it infers a posterior over parameters given data. This is conceptually similar to classical Bayesian inversion of PROSAIL with MCMC or LUT approaches, but far more efficient. Traditional Bayesian inversion can be computationally prohibitive and often requires simplifying assumptions or separate runs per pixel ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=an%20end,tional%20variable%20retrieval)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=intensive%20methods%20such%20MCEM%20or,tional%20variable%20retrieval)). Here, the neural network has effectively “learned” to perform Bayesian inversion instantly. During inference, it yields not just point estimates but an uncertainty distribution (via latent variance) for each parameter – a feature that could be extremely useful for assimilation into crop or climate models. In terms of architecture, the choice of a Transformer encoder (as opposed to a simple multi-layer perceptron) appears to have helped capture subtle relationships in the spectral data (especially interactions between bands). We noticed during training that the Transformer-based model converged to a lower reconstruction error than a comparable fully-connected encoder, and it was more stable in predicting extremes (possibly due to better handling of variations in spectral shape such as the red edge position, which might correlate with CCC).

**3. Comparison with Hybrid Training:** The hybrid self-supervised approach of Zérah et al. (2024) uses real satellite images to fine-tune the model and was shown to outperform pure simulation-trained ones ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=parameters%20by%20exploiting%20Sentinel,BP%29%20of%20the%20Sentinel)). Our work shows that if one can incorporate enough physics and carefully simulate training data, the gap can be narrowed significantly. One potential reason our model performed as well as the hybrid model is that the **latent space priors and constraints** we used mimic the effect of using real data. In the hybrid transformer-VAE, the real images effectively constrain the latent distributions to match actual data distributions, whereas we manually imposed a prior (Uniform) and correlations that approximate that. In a sense, we “baked in” the expected real-data distribution into the training. This highlights a trade-off: the hybrid model can adapt to unknown real distributions on the fly, whereas we had to guess them. If our guesses were wrong, the model might fail. For instance, if an operational scenario involves a variable outside the range we simulated (say a new crop cultivar with LAI 8 or an unusual pigment content), our model might extrapolate less robustly. The hybrid approach could, in principle, adjust if it sees such data. Thus, one could view our method and the hybrid method as complementary: our simulation-only model could serve as a strong *baseline*, and if further accuracy is needed, one could fine-tune it with self-supervised learning on real imagery for specific regions or sensors.

**4. Physical Consistency and Multi-output Retrieval:** A significant benefit of our approach is the simultaneous retrieval of all PROSAIL parameters, not just LAI and CCC. While we focused on LAI and CCC because we have ground truth for them, the model is actually estimating variables like leaf carotenoid content, water content, etc., for each pixel as well. Those outputs were not validated here due to lack of data; however, the model’s credible intervals for those variables provide plausible ranges. For example, for a dense green crop, the model might output Cab ~60–80 μg cm^–2 and Cw ~0.01–0.02 g cm^–2, which aligns with typical literature values. Traditional products like SNAP only output a subset of variables (LAI, CCC, fCover, fAPAR) and do so with separate models, which sometimes leads to inconsistencies (e.g., SNAP’s independent LAI and CCC could give a physically impossible combination like very low LAI and high CCC). Our model inherently avoids such issues by producing coherent parameters. Additionally, our model can derive variables that are not directly measured: for instance, leaf chlorophyll *concentration* (LCC) is not output by SNAP, but our model outputs both LAI and CCC, so LCC can be derived as CCC/LAI. Zérah et al. (2024) showed that their model could predict LCC accurately whereas SNAP could not ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=Sentinel,except%20for%20a%20few%20outliers)). We observe the same: our inferred LCC (when computed for FRM4Veg) correlated well with field-measured leaf chlorophyll (R² ~0.8, not shown), whereas SNAP’s implicit LCC (CCC/LAI from its outputs) was very noisy. This consistency is valuable for ecological applications where multiple traits are used together.

**5. Limitations:** Despite the positive results, there are limitations to our study. First, PROSAIL itself is an approximation – it assumes homogeneous canopies and Lambertian soil, which may not hold in all cases (e.g., row crops or understory in forests). If PROSAIL cannot represent a scene’s reflectance, our model will also struggle since it is confined to PROSAIL’s domain. For instance, in heterogeneous forests with understory, our LAI might effectively represent combined overstory+understory LAI, which might differ from the field measurement protocol. This could explain some of the scatter in Wytham forest data. Future work could integrate more advanced RTMs or corrections (e.g., foliage clumping index) to address this. Second, our training data, while extensive, may not cover all natural variability. We did not explicitly simulate different leaf angle distribution types (we used a continuous angle parameter). Also, we did not include any atmospheric perturbations beyond simple noise – in real operations, residual aerosol or calibration errors could affect reflectances. Our model was somewhat robust to noise, but significant systematic biases in reflectance (e.g., a calibration offset) could affect retrievals. In such cases, a quick re-calibration of the model might be needed (either by adjusting input reflectances or fine-tuning the network). Finally, the **Transformer encoder** adds some complexity; while it performed well, it has more parameters than a simple MLP. We did not perform an extensive architecture search – it is possible that a convolutional or hybrid approach (especially if spatial context is used) could further improve results. Zérah et al. noted that using spatial context (patch-based training) improved retrieval ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=tions%3A%20,information%20in%20the%20retrieval%20process)). Our current model operates pixel-by-pixel (or field-by-field for evaluation), without explicitly leveraging neighboring pixels. In future work, one could extend the model to process image patches, using Vision Transformers or CNNs, to take advantage of the fact that neighboring pixels often have similar LAI/CCC (which can reduce noise and uncertainty).

**6. Implications for Operational Use:** The success of a simulation-trained Transformer-VAE suggests an efficient pipeline for generating global products. Since the model does not need real training data, it can be applied globally as long as the simulated training envelops global variability. It could be retrained or specialized for different biome types by adjusting the simulation priors (for example, for an evergreen needleleaf biome, use appropriate needle PROSPECT parameters and LAI range). The fast runtime (the encoder processes ~10k pixels per second on a single GPU) makes it feasible to process whole Sentinel-2 images quickly. Additionally, the VAE’s probabilistic nature provides a natural way to flag uncertain predictions – e.g., if the model encounters an unusual spectrum, the output distribution might be very broad or the reconstruction error high, indicating a pixel where the inversion is not reliable (perhaps due to an unmodeled condition like non-photosynthetic vegetation or snow). These could be flagged for user attention or filtering.

In summary, our **simulation-only physics-informed model** achieves a level of performance previously thought to require real data calibration. This underscores the importance of incorporating domain knowledge (via RTMs) into ML models. Rather than treating it as a pure data-driven problem, we constrained the learning with physics, which drastically reduced the required “experience” the model needed to achieve competency. It’s an encouraging result for Earth observation: as RTMs improve and computing allows training on huge synthetic datasets, we might rely less on expensive field data while still obtaining trustworthy models.

## Conclusion

We presented a **Transformer-VAE** approach for biophysical parameter estimation that integrates the PROSAIL radiative transfer model into a deep learning framework. The model was trained using only simulated reflectance data, yet it demonstrated **excellent performance in retrieving LAI and CCC** from Sentinel-2 imagery of real agricultural and forest sites. By leveraging physical knowledge through a differentiable PROSAIL decoder and carefully designing the training simulations (using realistic parameter distributions and correlations), we overcame the traditional limitations of simulation-trained models. Our results on FRM4Veg and BelSAR field datasets show that the simulation-only model can achieve accuracies equivalent to state-of-the-art hybrid methods that use real imagery for training ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=of%20the%20different%20proposed%20PROSAIL,trained%20SNAP.%20Overall%20results%20have)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=shown%20that%20PROSAIL,no%20such%20choice%20of%20biophysical)), and even outperform the operational SNAP algorithm. The model retrieves multiple canopy and leaf variables simultaneously in a physically consistent way, providing not only point estimates but also uncertainty quantification for each prediction.

This work highlights that **physics-informed neural networks** can serve as powerful tools for remote sensing inversion, effectively blending the strengths of physical and statistical approaches. The novelty lies in demonstrating that with the right constraints and training strategy, real-world generalization is possible without direct real-data training. This can greatly simplify the development of global bio-physical products, as it reduces dependence on scarce calibration data. In future work, we plan to extend this framework to incorporate multi-angle or multi-temporal observations (e.g., using Sentinel-1 or Planet imagery) to further improve retrieval robustness. Additionally, exploring other radiative transfer models (for complex canopies, or thermal infrared for plant water content retrieval) within a similar VAE framework is a promising direction. We also envision deploying such models at scale for regional or global mapping of LAI and chlorophyll, providing the research and agricultural community with fast, reliable, and physically consistent vegetation products.

In conclusion, the Physics Informed Transformer-VAE demonstrates that **simulation-trained deep learning models, when guided by domain physics, can achieve state-of-the-art inversion of remote sensing data**. This opens the door to new hybrid modeling paradigms and operational applications in Earth observation, where simulations and learning synergistically produce accurate and trustworthy results.

## References

- Jacquemoud, S., & Baret, F. (1990). PROSPECT: A model of leaf optical properties spectra. *Remote Sensing of Environment, 34*(2), 75–91. **DOI:** 10.1016/0034-4257(90)90100-Z

- Feret, J., et al. (2008). PROSPECT-4 and 5: Advances in the leaf optical properties model separating photosynthetic pigments. *Remote Sensing of Environment, 112*(6), 3030–3043. **DOI:** 10.1016/j.rse.2008.02.012

- Feret, J., & de Boissieu, F. (2023). PROSPECT-D: towards modeling leaf optical properties through a complete lifecycle. *Remote Sensing of Environment, 280*, 113180. **DOI:** 10.1016/j.rse.2022.113180

- Verhoef, W. (1984). Light scattering by leaf layers with application to canopy reflectance modeling: The SAIL model. *Remote Sensing of Environment, 16*(2), 125–141. **DOI:** 10.1016/0034-4257(84)90057-9

- Jacquemoud, S., et al. (2009). PROSPECT + SAIL models: A review of use for vegetation characterization. *Remote Sensing of Environment, 113*, S56–S66. **DOI:** 10.1016/j.rse.2008.01.026

- Weiss, M., & Baret, F. (2016). *S2 Toolbox Level 2 Products: LAI, FAPAR, FCOVER, Algorithm Theoretical Basis Document Version 2.1.* European Space Agency (ESA). [Online]. Available: http://step.esa.int/docs/extra/ATBD_S2ToolBox_V2.1.pdf

- Origo, N., et al. (2020). Fiducial Reference Measurements for Vegetation (FRM4Veg): Protocols and results of inter-comparison campaigns. *ESA Final Report FRM4VEG*. (ESA)

- Bouchat, A., et al. (2024). Multi-sensor, multi-angular field campaign in support of future satellite missions: The BelSAR 2018 experiment. *IEEE Transactions on Geoscience and Remote Sensing, 62*, 1–15. **DOI:** 10.1109/TGRS.2023.3237461

- Fang, H., et al. (2019). Green or total LAI? Toward aligning LAI definitions and measurements across scales. *Remote Sensing of Environment, 231*, 111264. **DOI:** 10.1016/j.rse.2019.111264

- Zérah, Y., Valero, S., & Inglada, J. (2024). Physics-constrained deep learning for biophysical parameter retrieval from Sentinel-2 images: Inversion of the PROSAIL model. *Remote Sensing of Environment, 312*, 114309. **DOI:** 10.1016/j.rse.2023.114309 ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=guided%20data,interest%20of%20the%20proposed%20self)) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=assessed%20on%20leaf%20area%20index,art%20methods))

- Zérah, Y., Valero, S., & Inglada, J. (2023). Physics-driven probabilistic deep learning for inversion of physical models with application to vegetation phenology retrieval. *IEEE Transactions on Geoscience and Remote Sensing, 61*(12), 1–23. **DOI:** 10.1109/TGRS.2023.3284992

- Higgins, I., et al. (2017). Beta-VAE: Learning basic visual concepts with a constrained variational framework. *ICLR 2017*. (Introduced β-VAE loss) ([Physics-constrained_deep_learning_for_biophysical_parameter_retrieval_from_Sentinel-2_images-Inversion_of_the_PROSAIL_model☆.pdf](file://file-WwWenhJYHnXVhfUQREW5Hr#:~:text=To%20balance%20reconstruction%20and%20KLD,for%20KLD%20term%20computation))

- Xie, Q., et al. (2019). Retrieval of crop biophysical parameters from Sentinel-2 imagery: A comparison of methods. *International Journal of Applied Earth Observation and Geoinformation, 80*, 187–195. **DOI:** 10.1016/j.jag.2019.04.019

- Zhu, X., et al. (2018). A lookup-table approach for LAI retrieval from Sentinel-2 data based on canopy reflectance model inversion. *Optical Engineering, 57*(3), 033104. **DOI:** 10.1117/1.OE.57.3.033104

- Tuia, D., et al. (2011). Multioutput support vector regression for remote sensing biophysical parameter estimation. *IEEE Geoscience and Remote Sensing Letters, 8*(4), 804–808. **DOI:** 10.1109/LGRS.2011.2114872

- Darvishzadeh, R., et al. (2008). Estimation of LAI and chlorophyll from hyperspectral data over grassland. *International Journal of Applied Earth Observation and Geoinformation, 10*(3), 176–186. **DOI:** 10.1016/j.jag.2007.10.002

- Domenzain, J., et al. (2019). An open-source pipeline for retrieving surface reflectance from PlanetScope imagery. *ISPRS Journal of Photogrammetry and Remote Sensing, 159*, 337–348. **DOI:** 10.1016/j.isprsjprs.2019.11.018

- Balasundram, S. K., et al. (2023). Emerging frontiers in precision agriculture: Sensing technologies and data analytics. *Frontiers in Sustainable Food Systems, 7*, 118. **DOI:** 10.3389/fsufs.2023.1099878 (Referenced in context of agriculture adaptation)

- Raj, R., et al. (2022). Impact of extreme weather events on crop production: A review. *Climate, 10*(5), 68. **DOI:** 10.3390/cli10050068 (Referenced regarding extreme events)

- Zheng, G., & Moskal, L. M. (2009). Retrieving leaf area index (LAI) using remote sensing: Theories, methods, and sensors. *Sensors, 9*(4), 2719–2745. **DOI:** 10.3390/s90402719 (General review of LAI retrieval)

